{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f2de24bd-5afe-49af-8209-0ed4bc6f4e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bd975a37-f7b3-44e1-9c42-c5c258ee9835",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting snowflake\n",
      "  Downloading snowflake-0.7.0-py3-none-any.whl (1.5 kB)\n",
      "Collecting snowflake-core==0.7.0\n",
      "  Downloading snowflake_core-0.7.0-py3-none-any.whl (330 kB)\n",
      "     -------------------------------------- 330.1/330.1 kB 5.1 MB/s eta 0:00:00\n",
      "Collecting snowflake-legacy\n",
      "  Downloading snowflake_legacy-0.7.0-py3-none-any.whl (3.1 kB)\n",
      "Collecting atpublic>=4\n",
      "  Downloading atpublic-4.1.0-py3-none-any.whl (5.0 kB)\n",
      "Collecting pydantic>=1.10.7\n",
      "  Downloading pydantic-2.6.4-py3-none-any.whl (394 kB)\n",
      "     -------------------------------------- 394.9/394.9 kB 8.2 MB/s eta 0:00:00\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\mithunm\\appdata\\roaming\\python\\python311\\site-packages (from snowflake-core==0.7.0->snowflake) (2.8.2)\n",
      "Collecting snowflake-snowpark-python<2.0.0,>=1.5.0\n",
      "  Downloading snowflake_snowpark_python-1.14.0-py3-none-any.whl (419 kB)\n",
      "     -------------------------------------- 419.7/419.7 kB 6.5 MB/s eta 0:00:00\n",
      "Requirement already satisfied: urllib3 in c:\\users\\mithunm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from snowflake-core==0.7.0->snowflake) (2.2.1)\n",
      "Collecting annotated-types>=0.4.0\n",
      "  Downloading annotated_types-0.6.0-py3-none-any.whl (12 kB)\n",
      "Collecting pydantic-core==2.16.3\n",
      "  Downloading pydantic_core-2.16.3-cp311-none-win_amd64.whl (1.9 MB)\n",
      "     ---------------------------------------- 1.9/1.9 MB 9.2 MB/s eta 0:00:00\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in c:\\users\\mithunm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic>=1.10.7->snowflake-core==0.7.0->snowflake) (4.11.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\mithunm\\appdata\\roaming\\python\\python311\\site-packages (from python-dateutil>=2.8.2->snowflake-core==0.7.0->snowflake) (1.16.0)\n",
      "Requirement already satisfied: setuptools>=40.6.0 in c:\\users\\mithunm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from snowflake-snowpark-python<2.0.0,>=1.5.0->snowflake-core==0.7.0->snowflake) (65.5.0)\n",
      "Collecting wheel\n",
      "  Downloading wheel-0.43.0-py3-none-any.whl (65 kB)\n",
      "     ---------------------------------------- 65.8/65.8 kB ? eta 0:00:00\n",
      "Requirement already satisfied: snowflake-connector-python<4.0.0,>=3.6.0 in c:\\users\\mithunm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from snowflake-snowpark-python<2.0.0,>=1.5.0->snowflake-core==0.7.0->snowflake) (3.7.1)\n",
      "Collecting pyyaml\n",
      "  Downloading PyYAML-6.0.1-cp311-cp311-win_amd64.whl (144 kB)\n",
      "     -------------------------------------- 144.7/144.7 kB 8.4 MB/s eta 0:00:00\n",
      "Collecting cloudpickle==2.2.1\n",
      "  Downloading cloudpickle-2.2.1-py3-none-any.whl (25 kB)\n",
      "Requirement already satisfied: asn1crypto<2.0.0,>0.24.0 in c:\\users\\mithunm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from snowflake-connector-python<4.0.0,>=3.6.0->snowflake-snowpark-python<2.0.0,>=1.5.0->snowflake-core==0.7.0->snowflake) (1.5.1)\n",
      "Requirement already satisfied: cffi<2.0.0,>=1.9 in c:\\users\\mithunm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from snowflake-connector-python<4.0.0,>=3.6.0->snowflake-snowpark-python<2.0.0,>=1.5.0->snowflake-core==0.7.0->snowflake) (1.16.0)\n",
      "Requirement already satisfied: cryptography<43.0.0,>=3.1.0 in c:\\users\\mithunm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from snowflake-connector-python<4.0.0,>=3.6.0->snowflake-snowpark-python<2.0.0,>=1.5.0->snowflake-core==0.7.0->snowflake) (42.0.5)\n",
      "Requirement already satisfied: pyOpenSSL<25.0.0,>=16.2.0 in c:\\users\\mithunm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from snowflake-connector-python<4.0.0,>=3.6.0->snowflake-snowpark-python<2.0.0,>=1.5.0->snowflake-core==0.7.0->snowflake) (24.1.0)\n",
      "Requirement already satisfied: pyjwt<3.0.0 in c:\\users\\mithunm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from snowflake-connector-python<4.0.0,>=3.6.0->snowflake-snowpark-python<2.0.0,>=1.5.0->snowflake-core==0.7.0->snowflake) (2.8.0)\n",
      "Requirement already satisfied: pytz in c:\\users\\mithunm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from snowflake-connector-python<4.0.0,>=3.6.0->snowflake-snowpark-python<2.0.0,>=1.5.0->snowflake-core==0.7.0->snowflake) (2024.1)\n",
      "Requirement already satisfied: requests<3.0.0 in c:\\users\\mithunm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from snowflake-connector-python<4.0.0,>=3.6.0->snowflake-snowpark-python<2.0.0,>=1.5.0->snowflake-core==0.7.0->snowflake) (2.31.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\mithunm\\appdata\\roaming\\python\\python311\\site-packages (from snowflake-connector-python<4.0.0,>=3.6.0->snowflake-snowpark-python<2.0.0,>=1.5.0->snowflake-core==0.7.0->snowflake) (23.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\mithunm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from snowflake-connector-python<4.0.0,>=3.6.0->snowflake-snowpark-python<2.0.0,>=1.5.0->snowflake-core==0.7.0->snowflake) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\mithunm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from snowflake-connector-python<4.0.0,>=3.6.0->snowflake-snowpark-python<2.0.0,>=1.5.0->snowflake-core==0.7.0->snowflake) (3.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\mithunm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from snowflake-connector-python<4.0.0,>=3.6.0->snowflake-snowpark-python<2.0.0,>=1.5.0->snowflake-core==0.7.0->snowflake) (2024.2.2)\n",
      "Requirement already satisfied: filelock<4,>=3.5 in c:\\users\\mithunm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from snowflake-connector-python<4.0.0,>=3.6.0->snowflake-snowpark-python<2.0.0,>=1.5.0->snowflake-core==0.7.0->snowflake) (3.13.3)\n",
      "Requirement already satisfied: sortedcontainers>=2.4.0 in c:\\users\\mithunm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from snowflake-connector-python<4.0.0,>=3.6.0->snowflake-snowpark-python<2.0.0,>=1.5.0->snowflake-core==0.7.0->snowflake) (2.4.0)\n",
      "Requirement already satisfied: platformdirs<4.0.0,>=2.6.0 in c:\\users\\mithunm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from snowflake-connector-python<4.0.0,>=3.6.0->snowflake-snowpark-python<2.0.0,>=1.5.0->snowflake-core==0.7.0->snowflake) (3.11.0)\n",
      "Requirement already satisfied: tomlkit in c:\\users\\mithunm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from snowflake-connector-python<4.0.0,>=3.6.0->snowflake-snowpark-python<2.0.0,>=1.5.0->snowflake-core==0.7.0->snowflake) (0.12.4)\n",
      "Requirement already satisfied: pycparser in c:\\users\\mithunm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from cffi<2.0.0,>=1.9->snowflake-connector-python<4.0.0,>=3.6.0->snowflake-snowpark-python<2.0.0,>=1.5.0->snowflake-core==0.7.0->snowflake) (2.22)\n",
      "Installing collected packages: wheel, snowflake-legacy, pyyaml, pydantic-core, cloudpickle, atpublic, annotated-types, pydantic, snowflake-snowpark-python, snowflake-core, snowflake\n",
      "  Attempting uninstall: cloudpickle\n",
      "    Found existing installation: cloudpickle 3.0.0\n",
      "    Uninstalling cloudpickle-3.0.0:\n",
      "      Successfully uninstalled cloudpickle-3.0.0\n",
      "Successfully installed annotated-types-0.6.0 atpublic-4.1.0 cloudpickle-2.2.1 pydantic-2.6.4 pydantic-core-2.16.3 pyyaml-6.0.1 snowflake-0.7.0 snowflake-core-0.7.0 snowflake-legacy-0.7.0 snowflake-snowpark-python-1.14.0 wheel-0.43.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The script wheel.exe is installed in 'c:\\Users\\MithunM\\AppData\\Local\\Programs\\Python\\Python311\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "\n",
      "[notice] A new release of pip available: 22.3 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install snowflake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "254bd740-0390-4009-8362-84484b29a64e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from dotenv import load_dotenv\n",
    "import os\n",
    "import pymongo\n",
    "import snowflake.connector\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5317419c-885f-4c02-92c6-974613623fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables from .env file\n",
    "# load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e451a7c-c468-46d6-bcf6-ac72e040c9af",
   "metadata": {},
   "outputs": [],
   "source": [
    "mongo_connection_string =  \"mongodb+srv://finalproject:finalproject@finalproject.xa5ol.mongodb.net/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0be05bb1-315b-4056-b711-3390b5226e78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to MongoDB Atlas successfully!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['Project'] = 'test'\n",
    "\n",
    "try:\n",
    "    # Connect to MongoDB Atlas\n",
    "    mongo_client = pymongo.MongoClient(mongo_connection_string)\n",
    "    mongo_db = mongo_client[os.environ['Project']]\n",
    "    \n",
    "    # Print connection success message\n",
    "    print(\"Connected to MongoDB Atlas successfully!\")\n",
    "\n",
    "    # Now, you can perform further operations with mongo_client and mongo_db\n",
    "except pymongo.errors.ConnectionFailure as e:\n",
    "    # Print connection failure message\n",
    "    print(f\"Failed to connect to MongoDB Atlas: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "adbfaa6a-1de5-4d81-ac0f-9a60c0463be4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to Snowflake successfully!\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # Connect to Snowflake using environment variables\n",
    "    snowflake_conn = snowflake.connector.connect(\n",
    "        user=\"Mithun\",\n",
    "        password=\"Mithun123!!\",\n",
    "        account=\"lz05490.central-india.azure\",\n",
    "        warehouse=\"COMPUTE_WH\",\n",
    "        database=\"TIMESHEET\",\n",
    "        schema=\"FAKEDATA\",\n",
    "        role = \"ACCOUNTADMIN\"\n",
    "    )\n",
    "\n",
    "    # Print connection success message\n",
    "    print(\"Connected to Snowflake successfully!\")\n",
    "\n",
    "    # Now, you can perform further operations with snowflake_conn\n",
    "except snowflake.connector.errors.DatabaseError as e:\n",
    "    # Print connection failure message\n",
    "    print(f\"Failed to connect to Snowflake: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb50e6f9-da21-4151-9182-9a39c8949264",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "93decfc1-36a7-44a6-8871-0c9e0b870ba4",
   "metadata": {},
   "source": [
    "## Mongo to Stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "47f9243c-5d60-44c4-ab1f-21b25ba0ff8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data from collection 'feedbacks' written to 'staging_raw_data/feedbacks.csv'\n",
      "Data from collection 'users' written to 'staging_raw_data/users.csv'\n",
      "Data from collection 'timesheets' written to 'staging_raw_data/timesheets.csv'\n",
      "Data from collection 'projects' written to 'staging_raw_data/projects.csv'\n",
      "Data from collection 'allocateprojects' written to 'staging_raw_data/allocateprojects.csv'\n",
      "Data from collection 'projectallocation' written to 'staging_raw_data/projectallocation.csv'\n"
     ]
    }
   ],
   "source": [
    "# Create raw_data folder if it doesn't exist\n",
    "if not os.path.exists(\"staging_raw_data\"):\n",
    "    os.makedirs(\"staging_raw_data\")\n",
    "\n",
    "# Iterate over each collection\n",
    "for collection_name in mongo_db.list_collection_names():\n",
    "    # Retrieve data from collection\n",
    "    collection_data = list(mongo_db[collection_name].find())\n",
    "    \n",
    "    # Convert data to DataFrame\n",
    "    df = pd.DataFrame(collection_data)\n",
    "    \n",
    "    # Write DataFrame to CSV file\n",
    "    csv_file_path = f\"staging_raw_data/{collection_name}.csv\"\n",
    "    df.to_csv(csv_file_path, index=False)\n",
    "    print(f\"Data from collection '{collection_name}' written to '{csv_file_path}'\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b1ad9de4-c0f8-45c2-b93b-feae27a242ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close MongoDB connection\n",
    "mongo_client.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "379ae2bd-ae40-4d2a-a178-7ad079540d27",
   "metadata": {},
   "source": [
    "## Ingest Into Snowflake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "da4fbebe-df97-491f-a165-cb6b47dae705",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data from 'allocateprojects.csv' inserted into 'allocateprojects' table in Snowflake.\n",
      "Data from 'feedbacks.csv' inserted into 'feedbacks' table in Snowflake.\n",
      "Data from 'projectallocation.csv' inserted into 'projectallocation' table in Snowflake.\n",
      "Data from 'projects.csv' inserted into 'projects' table in Snowflake.\n",
      "Data from 'timesheets.csv' inserted into 'timesheets' table in Snowflake.\n",
      "Data from 'users.csv' inserted into 'users' table in Snowflake.\n"
     ]
    }
   ],
   "source": [
    "def sanitize_name(name):\n",
    "    # Replace invalid characters with underscores\n",
    "    return ''.join(c if c.isalnum() else '_' for c in name)\n",
    "if not os.path.exists(\"staging_raw_data\"):\n",
    "    print(\"No data to process. Exiting.\")\n",
    "    exit()\n",
    "\n",
    "# Iterate over each CSV file in the staging_raw_data folder\n",
    "for filename in os.listdir(\"staging_raw_data\"):\n",
    "    if filename.endswith(\".csv\"):\n",
    "        # Extract table name from filename (remove .csv extension) and sanitize it\n",
    "        table_name = sanitize_name(os.path.splitext(filename)[0])\n",
    "        \n",
    "        # Read CSV file into DataFrame\n",
    "        df = pd.read_csv(f\"staging_raw_data/{filename}\")\n",
    "        \n",
    "        # Replace NaN values with empty strings\n",
    "        df = df.fillna('')\n",
    "        \n",
    "        # Convert all data to string\n",
    "        df = df.astype(str)\n",
    "        \n",
    "        # Create table in Snowflake if it doesn't exist\n",
    "        snowflake_cursor = snowflake_conn.cursor()\n",
    "        \n",
    "        # Drop the table if it exists\n",
    "        snowflake_cursor.execute(f\"DROP TABLE IF EXISTS {table_name}\")\n",
    "        \n",
    "        # Create the table\n",
    "        create_table_query = f\"CREATE TABLE {table_name} (\"\n",
    "        for column in df.columns:\n",
    "            # Sanitize column names\n",
    "            safe_column_name = sanitize_name(column)\n",
    "            create_table_query += f'{safe_column_name} VARCHAR,'\n",
    "        create_table_query = create_table_query[:-1] + \")\"  # Remove trailing comma\n",
    "        snowflake_cursor.execute(create_table_query)\n",
    "        \n",
    "        # Prepare INSERT INTO statement\n",
    "        insert_query = f\"INSERT INTO {table_name} VALUES ({','.join(['%s'] * len(df.columns))})\"\n",
    "        \n",
    "        # Convert DataFrame to list of tuples (rows)\n",
    "        rows = [tuple(row) for row in df.itertuples(index=False)]\n",
    "        \n",
    "        # Execute bulk insert\n",
    "        snowflake_cursor.executemany(insert_query, rows)\n",
    "        snowflake_cursor.close()\n",
    "        \n",
    "        print(f\"Data from '{filename}' inserted into '{table_name}' table in Snowflake.\")\n",
    "\n",
    "# Commit the transaction\n",
    "snowflake_conn.commit()\n",
    "\n",
    "# Close Snowflake connection\n",
    "snowflake_conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "544e9785-9b49-434e-8096-9cb47e5f76e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df45f319",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6f44578",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "521e4dbe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d7728f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import snowflake.connector\n",
    "import psycopg2\n",
    "import csv\n",
    "from io import StringIO\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "snowflake_connection = snowflake.connector.connect(\n",
    "         \n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection to Snowflake successful!\n"
     ]
    }
   ],
   "source": [
    "snowflake_cursor = snowflake_connection.cursor()\n",
    "\n",
    "\n",
    "# Check Snowflake connection\n",
    "try:\n",
    "    snowflake_connection\n",
    "    print(\"Connection to Snowflake successful!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error connecting to Snowflake: {str(e)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection to PostgreSQL successful.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # Connect to PostgreSQL\n",
    "    pg_conn = psycopg2.connect(\n",
    "        dbname='testdb',\n",
    "        user='postgres',\n",
    "        password='password',\n",
    "        host='localhost',\n",
    "        port='5432'  # Default PostgreSQL port\n",
    "    )\n",
    "\n",
    "    # Create a cursor object using the connection\n",
    "    pg_cursor = pg_conn.cursor()\n",
    "    print(\"Connection to PostgreSQL successful.\")\n",
    "except psycopg2.Error as e:\n",
    "    print(\"Error connecting to PostgreSQL:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "pg_cursor.execute(\"SELECT table_name FROM information_schema.tables WHERE table_schema = 'public' AND table_type = 'BASE TABLE'\")\n",
    "tables = pg_cursor.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table 'tbl_skills' exported to CSV successfully.\n",
      "Table 'tbl_certificates' exported to CSV successfully.\n",
      "Table 'tbl_user_project' exported to CSV successfully.\n",
      "Table 'tbl_user' exported to CSV successfully.\n",
      "Table 'tbl_approver_user' exported to CSV successfully.\n",
      "Table 'tbl_user_certificate' exported to CSV successfully.\n",
      "Table 'tbl_user_skill' exported to CSV successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SwarnadeepPramanik\\AppData\\Local\\Temp\\ipykernel_11824\\4047154470.py:4: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(f'SELECT * FROM {table_name}', pg_conn)\n"
     ]
    }
   ],
   "source": [
    "for table in tables:\n",
    "    table_name = table[0]\n",
    "    # Read data from the table into a pandas DataFrame\n",
    "    df = pd.read_sql(f'SELECT * FROM {table_name}', pg_conn)\n",
    "    # Export DataFrame to CSV\n",
    "    df.to_csv(f'staging/{table_name}.csv', index=False)\n",
    "    print(f\"Table '{table_name}' exported to CSV successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "pg_conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ingestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "staging_folder = 'staging/'  # Change this to your actual staging folder path\n",
    "\n",
    "# Get a list of all CSV files in the staging folder\n",
    "csv_files = [file for file in os.listdir(staging_folder) if file.endswith('.csv')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tbl_approver_user'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.splitext(csv_files[0])[0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = pd.read_csv(os.path.join(staging_folder, csv_files[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table 'tbl_approver_user' created in Snowflake.\n",
      "Data inserted into table 'tbl_approver_user' in Snowflake.\n",
      "Table 'tbl_certificates' created in Snowflake.\n",
      "Data inserted into table 'tbl_certificates' in Snowflake.\n",
      "Table 'tbl_skills' created in Snowflake.\n",
      "Data inserted into table 'tbl_skills' in Snowflake.\n",
      "Table 'tbl_user' created in Snowflake.\n",
      "Data inserted into table 'tbl_user' in Snowflake.\n",
      "Table 'tbl_user_certificate' created in Snowflake.\n",
      "Data inserted into table 'tbl_user_certificate' in Snowflake.\n",
      "Table 'tbl_user_project' created in Snowflake.\n",
      "Data inserted into table 'tbl_user_project' in Snowflake.\n",
      "Table 'tbl_user_skill' created in Snowflake.\n",
      "Data inserted into table 'tbl_user_skill' in Snowflake.\n"
     ]
    }
   ],
   "source": [
    "for csv_file in csv_files:\n",
    "    table_name = os.path.splitext(csv_file)[0]  # Use CSV file name as table name\n",
    "    \n",
    "    # Read CSV file into DataFrame\n",
    "    df = pd.read_csv(os.path.join(staging_folder, csv_file))\n",
    "    \n",
    "    # Create table in Snowflake\n",
    "    create_table_query = f\"CREATE TABLE {table_name} (\"\n",
    "    for column in df.columns:\n",
    "        create_table_query += f\"{column} VARCHAR,\"\n",
    "    create_table_query = create_table_query[:-1]  # Remove trailing comma\n",
    "    create_table_query += \")\"\n",
    "\n",
    "    # print(create_table_query)\n",
    "    # break\n",
    "    snowflake_cursor.execute(create_table_query)\n",
    "    print(f\"Table '{table_name}' created in Snowflake.\")\n",
    "    \n",
    "    # Insert data into Snowflake table\n",
    "    snowflake_cursor.executemany(f\"INSERT INTO {table_name} VALUES ({','.join(['%s']*len(df.columns))})\", df.values.tolist())\n",
    "    print(f\"Data inserted into table '{table_name}' in Snowflake.\")\n",
    "    \n",
    "# Commit changes\n",
    "snowflake_connection.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close cursor and connection\n",
    "snowflake_connection.close()\n",
    "pg_conn.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
